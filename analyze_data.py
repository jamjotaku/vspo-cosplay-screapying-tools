import json
import os
import re
from datetime import datetime, timedelta, timezone

# --- 1. Tweet IDã‹ã‚‰æ™‚é–“ã‚’å¾©å…ƒã™ã‚‹é­”æ³• (Snowflake ID) ---
def get_tweet_time(tweet_id):
    try:
        # X(Twitter)ã®ç´€å…ƒ: 2010-11-04 01:42:54.657 UTC
        tw_epoch = 1288834974657
        timestamp_ms = (int(tweet_id) >> 22) + tw_epoch
        # UTC -> JST (+9æ™‚é–“)
        dt_utc = datetime.fromtimestamp(timestamp_ms / 1000, timezone.utc)
        dt_jst = dt_utc.astimezone(timezone(timedelta(hours=9)))
        return dt_jst
    except:
        return None

def analyze_data():
    input_file = 'collect.json'
    authors_file = 'authors.json'
    output_file = 'analysis.json'

    if not os.path.exists(input_file):
        print(f"âŒ {input_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with open(input_file, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    authors_data = {}
    if os.path.exists(authors_file):
        with open(authors_file, 'r', encoding='utf-8') as f:
            authors_data = json.load(f)

    # --- é›†è¨ˆç”¨å¤‰æ•°ã®åˆæœŸåŒ– ---
    valid_data = []
    
    # æ™‚é–“å¸¯ (0~23æ™‚)
    hourly_stats = {h: {'likes': 0, 'count': 0} for h in range(24)}
    
    # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°
    tag_stats = {} 
    
    # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” (ç¸¦é•·/æ¨ªé•·/æ­£æ–¹å½¢)
    aspect_stats = {
        'Portrait (ç¸¦é•·)': {'likes': 0, 'count': 0},
        'Landscape (æ¨ªé•·)': {'likes': 0, 'count': 0},
        'Square (æ­£æ–¹å½¢)': {'likes': 0, 'count': 0},
        'Unknown': {'likes': 0, 'count': 0}
    }

    # é­”æ³•ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (åˆ†æã—ãŸã„å˜èªãƒªã‚¹ãƒˆ)
    target_keywords = [
        "é€Ÿå ±", "å®…ã‚³ã‚¹", "åˆå‡ºã—", "ã‚¤ãƒ™ãƒ³ãƒˆ", "ã‚³ãƒŸã‚±", 
        "æé€ ", "ç§æœ", "å‹•ç”»", "è‡ªæ’®ã‚Š", "ã‚ªãƒ•ã‚·ãƒ§", 
        "ä¾›é¤Š", "å†æ²", "ããã»", "ã‚¹ã‚¿ã‚¸ã‚ª", "ã‚³ãƒ©ãƒœ"
    ]
    keyword_stats = {k: {'total_likes': 0, 'count': 0} for k in target_keywords}

    # å…¨ä½“å¹³å‡ç®—å‡ºç”¨
    global_total_likes = 0
    global_count = 0

    # --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ ---
    for d in raw_data:
        likes = d.get('like_count', 0)
        if likes == 0: continue # ã„ã„ã­0ã¯é™¤å¤–ï¼ˆå–å¾—ãƒŸã‚¹ç­‰ã®å¯èƒ½æ€§ï¼‰
        
        global_total_likes += likes
        global_count += 1

        # A. ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ± & Viral Score
        url_parts = d['url'].split('x.com/')
        username = "unknown"
        tweet_id = None
        if len(url_parts) > 1:
            parts = url_parts[1].split('/')
            username = parts[0]
            try:
                status_idx = parts.index('status')
                tweet_id = parts[status_idx + 1].split('?')[0]
            except: pass
            
        followers = authors_data.get(username, 0)
        viral_score = 0
        if followers > 100:
            viral_score = round(likes / followers, 3)

        # B. æ™‚é–“è§£æ
        hour = -1
        if tweet_id:
            dt = get_tweet_time(tweet_id)
            if dt:
                hour = dt.hour
                hourly_stats[hour]['likes'] += likes
                hourly_stats[hour]['count'] += 1

        # C. ãƒ†ã‚­ã‚¹ãƒˆè§£æ (ã‚¿ã‚° & ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰)
        text = d.get('text', '')
        
        # C-1. ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æŠ½å‡º
        tags = re.findall(r'[#ï¼ƒ]([a-zA-Z0-9_\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]+)', text)
        for tag in tags:
            # ä¸€èˆ¬çš„ã™ãã‚‹ã‚¿ã‚°ã¯é™¤å¤–ã—ã¦ã‚‚è‰¯ã„ãŒã€ä¸€æ—¦ã™ã¹ã¦é›†è¨ˆ
            if tag not in tag_stats: tag_stats[tag] = {'total_likes': 0, 'count': 0}
            tag_stats[tag]['total_likes'] += likes
            tag_stats[tag]['count'] += 1

        # C-2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        for kw in target_keywords:
            if kw in text:
                keyword_stats[kw]['total_likes'] += likes
                keyword_stats[kw]['count'] += 1

        # D. ç”»åƒã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”åˆ†æ (width/heightãŒã‚ã‚‹å ´åˆ)
        aspect_type = 'Unknown'
        if d.get('width') and d.get('height'):
            w, h = d['width'], d['height']
            ratio = w / h
            if ratio < 0.9: aspect_type = 'Portrait (ç¸¦é•·)'
            elif ratio > 1.1: aspect_type = 'Landscape (æ¨ªé•·)'
            else: aspect_type = 'Square (æ­£æ–¹å½¢)'
            
            # ãƒ‡ãƒ¼ã‚¿è‡ªä½“ã«ãƒ©ãƒ™ãƒ«ã‚’è¨˜éŒ²ã—ã¦ãŠã
            d['aspect_type'] = aspect_type

        # é›†è¨ˆåŠ ç®—
        if aspect_type in aspect_stats:
            aspect_stats[aspect_type]['likes'] += likes
            aspect_stats[aspect_type]['count'] += 1

        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆã«è¿½åŠ 
        d_copy = d.copy()
        d_copy['followers'] = followers
        d_copy['viral_score'] = viral_score
        d_copy['posted_hour'] = hour
        d_copy['aspect_type'] = aspect_type
        valid_data.append(d_copy)

    # --- é›†è¨ˆçµæœã®æ•´å½¢ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä½œæˆ ---
    
    # 0. å…¨ä½“å¹³å‡ (åŸºæº–å€¤)
    global_avg = int(global_total_likes / global_count) if global_count > 0 else 0

    # 1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ©ãƒ³ã‚­ãƒ³ã‚° (å€ç‡ä»˜ã)
    keyword_ranking = []
    for kw, s in keyword_stats.items():
        if s['count'] > 0:
            avg = int(s['total_likes'] / s['count'])
            multiplier = round(avg / global_avg, 2) if global_avg > 0 else 0
            keyword_ranking.append({
                'keyword': kw, 'avg_likes': avg, 'count': s['count'], 'multiplier': multiplier
            })
    keyword_ranking.sort(key=lambda x: x['avg_likes'], reverse=True)

    # 2. ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãƒ©ãƒ³ã‚­ãƒ³ã‚° (3ä»¶ä»¥ä¸Š)
    tag_ranking = []
    for tag, s in tag_stats.items():
        if s['count'] >= 3:
            avg = int(s['total_likes'] / s['count'])
            tag_ranking.append({'tag': tag, 'avg_likes': avg, 'count': s['count']})
    tag_ranking.sort(key=lambda x: x['avg_likes'], reverse=True)

    # 3. ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ãƒ¬ãƒãƒ¼ãƒˆ
    aspect_report = []
    for atype, s in aspect_stats.items():
        if s['count'] > 0 and atype != 'Unknown':
            avg = int(s['likes'] / s['count'])
            aspect_report.append({'type': atype, 'avg': avg, 'count': s['count']})
    aspect_report.sort(key=lambda x: x['avg'], reverse=True)

    # 4. æ™‚é–“å¸¯ãƒ¬ãƒãƒ¼ãƒˆ
    hourly_report = []
    for h in range(24):
        s = hourly_stats[h]
        avg = int(s['likes'] / s['count']) if s['count'] > 0 else 0
        hourly_report.append({'hour': h, 'avg_likes': avg, 'count': s['count']})

    # 5. ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Impression 100ä»¥ä¸Š)
    with_imp = [d for d in valid_data if d.get('impression_count', 0) > 100]
    engagement_ranking = []
    for d in with_imp:
        rate = (d['like_count'] / d['impression_count']) * 100
        d_copy = d.copy()
        d_copy['rate'] = round(rate, 2)
        engagement_ranking.append(d_copy)
    engagement_ranking.sort(key=lambda x: x['rate'], reverse=True)

    # 6. Viral Score ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    viral_ranking = sorted(valid_data, key=lambda x: x['viral_score'], reverse=True)[:50]
    
    # 7. å˜ç´”ã„ã„ã­ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    like_ranking = sorted(valid_data, key=lambda x: x['like_count'], reverse=True)[:50]

    # 8. ãƒ¡ãƒ³ãƒãƒ¼åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    member_stats = {}
    for d in valid_data:
        name = d['member_name']
        if name not in member_stats: member_stats[name] = {'total_likes': 0, 'count': 0}
        member_stats[name]['total_likes'] += d['like_count']
        member_stats[name]['count'] += 1

    member_ranking = []
    for name, s in member_stats.items():
        if s['count'] >= 3:
            member_ranking.append({'name': name, 'avg': int(s['total_likes']/s['count'])})
    member_ranking.sort(key=lambda x: x['avg'], reverse=True)

    # --- JSONä¿å­˜ ---
    result = {
        'updated_at': datetime.now().strftime('%Y/%m/%d %H:%M'),
        'total_analyzed': len(valid_data),
        'total_records': len(raw_data),
        'global_avg': global_avg,
        'keyword_ranking': keyword_ranking,
        'tag_ranking': tag_ranking[:20],
        'aspect_report': aspect_report,     # æ§‹å›³åˆ†æ
        'hourly_report': hourly_report,     # æ™‚é–“åˆ†æ
        'engagement_ranking': engagement_ranking[:30],
        'viral_ranking': viral_ranking,
        'like_ranking': like_ranking,
        'member_ranking': member_ranking
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("-" * 30)
    print(f"âœ… åˆ†æã‚³ãƒ³ãƒ—ãƒªãƒ¼ãƒˆï¼")
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ•°: {len(valid_data)}ä»¶")
    print(f"â° æ™‚é–“è§£æ: å®Œäº†")
    print(f"ğŸ—ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {len(keyword_ranking)}å€‹ã®å˜èªã‚’åˆ†æ")
    print(f"ğŸ“¸ æ§‹å›³åˆ†æ: {len(aspect_report)}ç¨®é¡ã®æ¯”ç‡ã‚’é›†è¨ˆ")
    print("-" * 30)

if __name__ == "__main__":
    analyze_data()