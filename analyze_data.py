import json
import os
import re
from datetime import datetime
from collections import Counter

# --- è¨­å®š ---
INPUT_FILE = 'collect.json'
OUTPUT_FILE = 'analysis.json'

# ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®šç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
LOCATION_KEYWORDS = {
    "Event": [
        "ã‚³ãƒŸã‚±", "C9", "C10", "å¤ã‚³ãƒŸ", "å†¬ã‚³ãƒŸ", 
        "ã‚¢ã‚³ã‚¹ã‚¿", "acosta", "æ± ãƒãƒ­", "ã¨ãªã‚³ã‚¹", 
        "è¶…ä¼šè­°", "ãƒ‹ã‚³è¶…", "ãƒ©ã‚°ã‚³ã‚¹", "ãƒ¯ãƒ³ãƒ•ã‚§ã‚¹", 
        "ãƒ›ã‚³ã‚³ã‚¹", "ãƒ“ãƒ“ã‚³ã‚¹", "ã‚¹ãƒˆãƒ•ã‚§ã‚¹", "a!"
    ],
    "Studio": [
        "ã‚¹ã‚¿ã‚¸ã‚ª", "studio", "æ’®", "æ’®å½±ä¼š", 
        "å®…ã‚³ã‚¹", "å®¶", "è‡ªæ’®ã‚Š", "ã‚»ãƒ«ãƒ•ã‚£ãƒ¼", "ç¬¹å¡š"
    ]
}

def analyze_data():
    print("ğŸš€ åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")

    if not os.path.exists(INPUT_FILE):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {INPUT_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        try:
            data = json.load(f)
        except json.JSONDecodeError:
            print("âŒ ã‚¨ãƒ©ãƒ¼: JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã¾ã™")
            return

    # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ï¼ˆã„ã„ã­æ•°ãŒå–å¾—ã§ãã¦ã„ã‚‹ã‚‚ã®ï¼‰ã®ã¿æŠ½å‡º
    valid_data = [d for d in data if d.get('like_count', 0) > 0]
    total_posts = len(valid_data)
    
    if total_posts == 0:
        print("âš ï¸ æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ï¼ˆã„ã„ã­ > 0ï¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚fetch_metrics.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    # å…¨ä½“å¹³å‡ã®ç®—å‡º
    total_likes = sum(d['like_count'] for d in valid_data)
    global_avg = int(total_likes / total_posts)

    # --- é›†è¨ˆç”¨å¤‰æ•°ã®åˆæœŸåŒ– ---
    # 0~23æ™‚ã®ç®±ã‚’ç”¨æ„
    hourly_stats = {h: {'likes': [], 'count': 0} for h in range(24)}
    
    # æ§‹å›³ã”ã¨ã®ç®±
    aspect_stats = {
        'Portrait': [], 
        'Landscape': [], 
        'Square': [], 
        'Unknown': []
    }
    
    # ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã”ã¨ã®ç®±
    location_stats = {
        'Event': {'likes': [], 'count': 0},
        'Studio/Home': {'likes': [], 'count': 0},
        'Others': {'likes': [], 'count': 0}
    }
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥é›†è¨ˆç”¨
    char_stats = {} 
    
    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”¨ãƒªã‚¹ãƒˆ
    ranking_data = []

    print(f"ğŸ“Š {total_posts} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...")

    for item in valid_data:
        likes = item['like_count']
        followers = item.get('follower_count', 0)
        text = item.get('text', "")
        url = item.get('url', "")
        
        # 1. æ™‚é–“å¸¯åˆ†æ
        try:
            dt = datetime.fromisoformat(item['created_at'])
            hour = dt.hour
            hourly_stats[hour]['likes'].append(likes)
            hourly_stats[hour]['count'] += 1
        except:
            pass # æ—¥ä»˜å½¢å¼ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—

        # 2. æ§‹å›³åˆ†æ
        dims = item.get('dimensions')
        label = 'Unknown'
        if dims and dims.get('height', 0) > 0:
            w, h = dims['width'], dims['height']
            ratio = w / h
            if 0.9 <= ratio <= 1.1: label = 'Square'
            elif ratio < 0.9: label = 'Portrait'
            else: label = 'Landscape'
        aspect_stats[label].append(likes)

        # 3. ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤å®š
        loc_label = 'Others'
        if any(k in text for k in LOCATION_KEYWORDS['Event']):
            loc_label = 'Event'
        elif any(k in text for k in LOCATION_KEYWORDS['Studio']):
            loc_label = 'Studio/Home'
        
        location_stats[loc_label]['likes'].append(likes)
        location_stats[loc_label]['count'] += 1

        # 4. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã¨ã‚³ã‚¹ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼IDã®åˆ†é›¢
        # memberã‚­ãƒ¼ã€ã¾ãŸã¯queryã‚­ãƒ¼ã‚’ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã¨ã—ã¦ä½¿ç”¨
        char_name = item.get('query') or item.get('member') or 'Unknown'
        
        # URLã‹ã‚‰ã‚³ã‚¹ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼IDã‚’æŠ½å‡º
        cos_id = 'Unknown'
        match = re.search(r'(?:twitter|x)\.com/([^/]+)/status', url)
        if match:
            cos_id = match.group(1)

        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥é›†è¨ˆ
        if char_name not in char_stats:
            char_stats[char_name] = {'likes': [], 'count': 0}
        char_stats[char_name]['likes'].append(likes)
        char_stats[char_name]['count'] += 1

        # 5. Viral Score (æ‹¡æ•£åŠ¹ç‡) è¨ˆç®—
        # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼0ã®å ´åˆã¯0ç‚¹ã¨ã™ã‚‹ (ã‚¨ãƒ©ãƒ¼å›é¿)
        viral_score = 0
        if followers > 0:
            viral_score = round((likes / followers) * 100, 2)
        
        ranking_data.append({
            'character_name': char_name,
            'cosplayer_name': cos_id,
            'like_count': likes,
            'followers': followers,
            'viral_score': viral_score,
            'url': url,
            'location': loc_label,
            'text': text[:50] + "..." if text else ""
        })

    # --- ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ (å®‰å…¨ãªè¨ˆç®—å‡¦ç†) ---

    # A. æ™‚é–“å¸¯ãƒ¬ãƒãƒ¼ãƒˆ
    hourly_report = []
    for h in range(24):
        data = hourly_stats[h]
        avg = int(sum(data['likes']) / len(data['likes'])) if data['likes'] else 0
        hourly_report.append({'hour': h, 'avg_likes': avg, 'count': data['count']})

    # B. æ§‹å›³ãƒ¬ãƒãƒ¼ãƒˆ
    aspect_report = []
    for type_name, likes_list in aspect_stats.items():
        avg = int(sum(likes_list) / len(likes_list)) if likes_list else 0
        aspect_report.append({'type': type_name, 'avg': avg, 'count': len(likes_list)})

    # C. ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ
    location_report = []
    for loc_name, data in location_stats.items():
        avg = int(sum(data['likes']) / len(data['likes'])) if data['likes'] else 0
        # å…¨ä½“å¹³å‡ã¨ã®æ¯”è¼ƒå€ç‡
        multiplier = round(avg / global_avg, 2) if global_avg > 0 else 0
        location_report.append({
            'location': loc_name, 
            'avg': avg, 
            'count': data['count'],
            'multiplier': multiplier
        })

    # D. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚° (å¹³å‡ã„ã„ã­é †)
    char_ranking = []
    for name, data in char_stats.items():
        avg = int(sum(data['likes']) / len(data['likes'])) if data['likes'] else 0
        char_ranking.append({'name': name, 'avg': avg, 'count': data['count']})
    # ä¸¦ã³æ›¿ãˆ
    char_ranking.sort(key=lambda x: x['avg'], reverse=True)

    # E. Viral Efficiency ãƒ©ãƒ³ã‚­ãƒ³ã‚° (ã‚¹ã‚³ã‚¢é †)
    ranking_data.sort(key=lambda x: x['viral_score'], reverse=True)
    # Top 50ã®ã¿ä¿å­˜ã—ã¦å®¹é‡å‰Šæ¸›
    viral_ranking = ranking_data[:50]

    # --- å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä½œæˆ ---
    output = {
        'updated_at': datetime.now().strftime('%Y/%m/%d %H:%M'),
        'total_analyzed': len(ranking_data),
        'total_records': len(data),
        'global_avg': global_avg,
        'hourly_report': hourly_report,
        'aspect_report': aspect_report,
        'location_report': location_report,
        'member_ranking': char_ranking,
        'viral_ranking': viral_ranking
    }

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    # å®Œäº†ãƒ­ã‚°
    print("-" * 30)
    print(f"âœ¨ åˆ†æå®Œäº†ï¼ (Avg: {global_avg} Likes)")
    if char_ranking:
        top_c = char_ranking[0]
        print(f"ğŸ‘‘ Top Character: {top_c['name']} (Avg: {top_c['avg']})")
    if viral_ranking:
        top_v = viral_ranking[0]
        print(f"ğŸš€ Top Viral Post: {top_v['viral_score']}% Efficiency (@{top_v['cosplayer_name']})")
    print("-" * 30)

if __name__ == "__main__":
    analyze_data()